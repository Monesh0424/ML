{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train,y_train),(X_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 17:28:58.804162 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:72: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0731 17:28:58.821609 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0731 17:28:58.825296 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4048: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0731 17:28:58.964091 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3878: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0731 17:28:58.966944 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0731 17:28:58.976054 139756072306496 deprecation.py:506] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0731 17:28:59.120627 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:172: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0731 17:28:59.253648 139756072306496 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/optimizers.py:782: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0731 17:28:59.370660 139756072306496 deprecation.py:323] From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('CNN model for image classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1562/1562 [==============================] - 44s 28ms/step - loss: 1.7949 - acc: 0.3564\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - 41s 27ms/step - loss: 1.7104 - acc: 0.3863\n",
      "Epoch 3/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.6820 - acc: 0.3969\n",
      "Epoch 4/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.6642 - acc: 0.4072\n",
      "Epoch 5/50\n",
      "1562/1562 [==============================] - 41s 26ms/step - loss: 1.6402 - acc: 0.4151\n",
      "Epoch 6/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.6263 - acc: 0.4219\n",
      "Epoch 7/50\n",
      "1562/1562 [==============================] - 43s 27ms/step - loss: 1.6212 - acc: 0.4198\n",
      "Epoch 8/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.6091 - acc: 0.4234\n",
      "Epoch 9/50\n",
      "1562/1562 [==============================] - 43s 28ms/step - loss: 1.5922 - acc: 0.4350\n",
      "Epoch 10/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.5922 - acc: 0.4373\n",
      "Epoch 11/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.5891 - acc: 0.4364\n",
      "Epoch 12/50\n",
      "1562/1562 [==============================] - 52s 33ms/step - loss: 1.5794 - acc: 0.4388\n",
      "Epoch 13/50\n",
      "1562/1562 [==============================] - 51s 32ms/step - loss: 1.5916 - acc: 0.4389\n",
      "Epoch 14/50\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.5801 - acc: 0.4429\n",
      "Epoch 15/50\n",
      "1562/1562 [==============================] - 46s 30ms/step - loss: 1.5853 - acc: 0.4386\n",
      "Epoch 16/50\n",
      "1562/1562 [==============================] - 43s 28ms/step - loss: 1.5852 - acc: 0.4397\n",
      "Epoch 17/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.5851 - acc: 0.4408\n",
      "Epoch 18/50\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.5832 - acc: 0.4421\n",
      "Epoch 19/50\n",
      "1562/1562 [==============================] - 43s 28ms/step - loss: 1.5873 - acc: 0.4434\n",
      "Epoch 20/50\n",
      "1562/1562 [==============================] - 44s 28ms/step - loss: 1.5744 - acc: 0.4464\n",
      "Epoch 21/50\n",
      "1562/1562 [==============================] - 45s 28ms/step - loss: 1.5892 - acc: 0.4436\n",
      "Epoch 22/50\n",
      "1562/1562 [==============================] - 44s 28ms/step - loss: 1.5925 - acc: 0.4436\n",
      "Epoch 23/50\n",
      "1562/1562 [==============================] - 44s 28ms/step - loss: 1.5754 - acc: 0.4458\n",
      "Epoch 24/50\n",
      "1562/1562 [==============================] - 43s 27ms/step - loss: 1.5899 - acc: 0.4405\n",
      "Epoch 25/50\n",
      "1562/1562 [==============================] - 43s 28ms/step - loss: 1.5830 - acc: 0.4450\n",
      "Epoch 26/50\n",
      "1562/1562 [==============================] - 42s 27ms/step - loss: 1.5816 - acc: 0.4435\n",
      "Epoch 27/50\n",
      "1562/1562 [==============================] - 43s 27ms/step - loss: 1.5993 - acc: 0.4381\n",
      "Epoch 28/50\n",
      "1562/1562 [==============================] - 53s 34ms/step - loss: 1.5924 - acc: 0.4427\n",
      "Epoch 29/50\n",
      "1562/1562 [==============================] - 55s 35ms/step - loss: 1.5933 - acc: 0.4399\n",
      "Epoch 30/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.5904 - acc: 0.4403\n",
      "Epoch 31/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.5971 - acc: 0.4383\n",
      "Epoch 32/50\n",
      "1562/1562 [==============================] - 46s 29ms/step - loss: 1.5868 - acc: 0.4413\n",
      "Epoch 33/50\n",
      "1562/1562 [==============================] - 45s 29ms/step - loss: 1.5900 - acc: 0.4417\n",
      "Epoch 34/50\n",
      "1562/1562 [==============================] - 53s 34ms/step - loss: 1.5963 - acc: 0.4416\n",
      "Epoch 35/50\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.5798 - acc: 0.4439\n",
      "Epoch 36/50\n",
      "1562/1562 [==============================] - 46s 30ms/step - loss: 1.5907 - acc: 0.4452\n",
      "Epoch 37/50\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.5906 - acc: 0.4419\n",
      "Epoch 38/50\n",
      "1562/1562 [==============================] - 51s 33ms/step - loss: 1.5857 - acc: 0.4453\n",
      "Epoch 39/50\n",
      "1562/1562 [==============================] - 49s 31ms/step - loss: 1.5784 - acc: 0.4451\n",
      "Epoch 40/50\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.5983 - acc: 0.4406\n",
      "Epoch 41/50\n",
      "1562/1562 [==============================] - 46s 29ms/step - loss: 1.5935 - acc: 0.4431\n",
      "Epoch 42/50\n",
      "1562/1562 [==============================] - 45s 29ms/step - loss: 1.5957 - acc: 0.4453\n",
      "Epoch 43/50\n",
      "1562/1562 [==============================] - 48s 30ms/step - loss: 1.6106 - acc: 0.4373\n",
      "Epoch 44/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.6038 - acc: 0.4438\n",
      "Epoch 45/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.6152 - acc: 0.4405\n",
      "Epoch 46/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.6337 - acc: 0.4332\n",
      "Epoch 47/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.6480 - acc: 0.4257\n",
      "Epoch 48/50\n",
      "1562/1562 [==============================] - 48s 31ms/step - loss: 1.6323 - acc: 0.4344\n",
      "Epoch 49/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.6323 - acc: 0.4372\n",
      "Epoch 50/50\n",
      "1562/1562 [==============================] - 47s 30ms/step - loss: 1.6475 - acc: 0.4283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b31276b00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "generator = ImageDataGenerator(rotation_range = 90  , horizontal_flip=True , vertical_flip=True)\n",
    "generator.fit(X_train)\n",
    "model.fit_generator(generator.flow(X_train,y_train,batch_size=32),epochs=50,steps_per_epoch=1562) # steps per epoch = no.of samples//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 251us/step\n",
      "test accuracy : 0.4461\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test)\n",
    "print('test accuracy : {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps per epoch = no. of total samples / batch size\n",
    "\n",
    "Keras' generators are infinite.\n",
    "\n",
    "Because of this, Keras cannot know by itself how many batches the generators should yield to complete one epoch.\n",
    "\n",
    "When you have a static number of samples, it makes perfect sense to use samples//batch_size for one epoch. \n",
    "But you may want to use a generator that performs random data augmentation for instance. \n",
    "And because of the random process, you will never have two identical training epochs. There isn't then a clear limit.\n",
    "\n",
    "So, these parameters in fit_generator allow you to control the yields per epoch as you wish, although in standard cases \n",
    "you'll probably keep to the most obvious option i.e samples // batch_size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
