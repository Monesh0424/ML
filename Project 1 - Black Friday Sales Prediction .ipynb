{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "\n",
    "A retail company “ABC Private Limited” wants to understand the customer purchase behaviour (specifically, purchase amount) \n",
    "against various products of different categories.\n",
    "\n",
    "They want to build a model to predict the purchase amount of customer against various products which will help them to \n",
    "create personalized offer for customers against different products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('train.csv')\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      "User_ID                       550068 non-null int64\n",
      "Product_ID                    550068 non-null object\n",
      "Gender                        550068 non-null object\n",
      "Age                           550068 non-null object\n",
      "Occupation                    550068 non-null int64\n",
      "City_Category                 550068 non-null object\n",
      "Stay_In_Current_City_Years    550068 non-null object\n",
      "Marital_Status                550068 non-null int64\n",
      "Product_Category_1            550068 non-null int64\n",
      "Product_Category_2            376430 non-null float64\n",
      "Product_Category_3            166821 non-null float64\n",
      "Purchase                      550068 non-null int64\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 50.4+ MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) There are 550068 instances.\n",
    "2) There are missing values in \"Product_Category_2\" and \"Product_Category_3\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    550068.000000\n",
       "mean       9263.968713\n",
       "std        5023.065394\n",
       "min          12.000000\n",
       "25%        5823.000000\n",
       "50%        8047.000000\n",
       "75%       12054.000000\n",
       "max       23961.000000\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Purchase'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1 = sales.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-35    219587\n",
       "36-45    110013\n",
       "18-25     99660\n",
       "46-50     45701\n",
       "51-55     38501\n",
       "55+       21504\n",
       "0-17      15102\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_1['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --> Creating Custom Column Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "\n",
    "class ColumnTransfomer(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self , X = True):\n",
    "        self.X = X\n",
    "        \n",
    "    def fit(self , X):\n",
    "        return self   # Do nothing\n",
    "    \n",
    "    def transform(self,X):\n",
    "        \n",
    "        x = {'0-17':0 , '18-25':1 , '26-35':2 , '36-45':3 , '46-50':4 , '51-55':5 , '55+':6}\n",
    "        X['Age'] = X['Age'].map(x)   # Encoding feature 'Age'.\n",
    "        X['Gender'] = X['Gender'].map({'M':0 , 'F':1})   # Label Encoding feature 'Gender'.\n",
    "        X.drop('Occupation',inplace=True,axis=1) # Dropping feature 'Occupation'.\n",
    "        X.drop('City_Category',inplace = True , axis=1) # Dropping feature 'City_Category'.\n",
    "        X.drop('Stay_In_Current_City_Years',inplace=True,axis=1)   \n",
    "        X.drop('User_ID',inplace=True,axis=1)\n",
    "        X.drop('Product_ID',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) We removed Occupation because , maximum purchase amount in the data is app. 24000 which is a reasonable amount to be spent.\n",
    "   So considering Ocuupation as unwanted data , it is removed.\n",
    "    \n",
    "2) Considering this is ONLINE platform, features 'City_category' and 'Stay_In_Current_City_Years' ,does not effect in   predicting purchase amount. So dropping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans = ColumnTransfomer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans.fit_transform(sales_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Marital_Status  Product_Category_1  Product_Category_2  \\\n",
       "0       1    0               0                   3                 NaN   \n",
       "1       1    0               0                   1                 6.0   \n",
       "2       1    0               0                  12                 NaN   \n",
       "3       1    0               0                  12                14.0   \n",
       "4       0    6               0                   8                 NaN   \n",
       "\n",
       "   Product_Category_3  Purchase  \n",
       "0                 NaN      8370  \n",
       "1                14.0     15200  \n",
       "2                 NaN      1422  \n",
       "3                 NaN      1057  \n",
       "4                 NaN      7969  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Creating pipelines to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute' , SimpleImputer(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7969.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Marital_Status  Product_Category_1  Product_Category_2  \\\n",
       "0     1.0  0.0             0.0                 3.0                 8.0   \n",
       "1     1.0  0.0             0.0                 1.0                 6.0   \n",
       "2     1.0  0.0             0.0                12.0                 8.0   \n",
       "3     1.0  0.0             0.0                12.0                14.0   \n",
       "4     0.0  6.0             0.0                 8.0                 8.0   \n",
       "\n",
       "   Product_Category_3  Purchase  \n",
       "0                16.0    8370.0  \n",
       "1                14.0   15200.0  \n",
       "2                16.0    1422.0  \n",
       "3                16.0    1057.0  \n",
       "4                16.0    7969.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pipeline.fit_transform(sales_1)\n",
    "final_data = pd.DataFrame(data=final_data,columns=sales_1.columns)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Seperating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = final_data.drop('Purchase',axis=1)\n",
    "label = final_data[['Purchase']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with out scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(feat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "tree_pred = tree.predict(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2920.8172611810487"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "np.sqrt(metrics.mean_squared_error(label,tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Decision tree\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree , feat , label , scoring = 'neg_mean_squared_error',cv=10)\n",
    "rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "def display_scores(scores):\n",
    "    print('scores:' , scores)\n",
    "    print('Mean:' , scores.mean())\n",
    "    print('std dev' , scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [2949.28730565 2980.22110854 2968.95915914 2942.16244122 2972.71465836\n",
      " 2955.39370966 2955.82911807 2970.57421418 2976.29756072 2971.60054827]\n",
      "Mean: 2964.30398238008\n",
      "std dev 12.03798720020312\n"
     ]
    }
   ],
   "source": [
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "    1) RMSE on training data - 2920\n",
    "    2) RMSE on validation data - 2964\n",
    "    3) Model is performing well on training data but not able to generalise on validation data.\n",
    "    4) Model might be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pline = Pipeline([\n",
    "    ('scale' , MinMaxScaler())\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_feat = pline.fit_transform(feat)\n",
    "scaled_label = pline.fit_transform(label)\n",
    "scaled_label = scaled_label.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(scaled_feat,scaled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12195988396931182"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2=tree.predict(scaled_feat)\n",
    "np.sqrt(metrics.mean_squared_error(scaled_label,pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = cross_val_score(tree , scaled_feat , scaled_label , scoring = 'neg_mean_squared_error',cv=10)\n",
    "rmse_scores_2 = np.sqrt(-scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.12314573 0.12444032 0.12397586 0.12285119 0.12412688 0.12341069\n",
      " 0.12341922 0.12403764 0.12427649 0.12408055]\n",
      "Mean: 0.12377645767150161\n",
      "std dev 0.0005029226531576532\n"
     ]
    }
   ],
   "source": [
    "display_scores(rmse_scores_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation after scaling the data: \n",
    "    1) RMSE on training data after scaling - 0.121\n",
    "    2) RMSE on validation data after scaling - 0.123\n",
    "    3) Model performance is improved after scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---> Finding best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [\n",
    "    {'n_estimators':[3,6] , 'max_features':[2,6]},\n",
    "    {'bootstrap':[False] , 'n_estimators':[3,10] , 'max_features':[2,3,4]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = forest , param_grid = grid , scoring = 'neg_mean_squared_error' , cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 6], 'n_estimators': [3, 6]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(scaled_feat,scaled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> Evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12403743307177573 {'max_features': 2, 'n_estimators': 3}\n",
      "0.12390593248129604 {'max_features': 2, 'n_estimators': 6}\n",
      "0.12401624463574172 {'max_features': 6, 'n_estimators': 3}\n",
      "0.12388500791261076 {'max_features': 6, 'n_estimators': 6}\n",
      "0.12385929807470066 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.12384147604741927 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.12383192830790074 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.12382952738255366 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.12383924097008901 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.12383485787130602 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "for mean_score , params in zip(scores['mean_test_score'] , scores['params']):\n",
    "    print(np.sqrt(-mean_score) , params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation - Validation score of Random forest is similar to decision tree's validation score.\n",
    "            - No change in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(feat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "pred_lm = lm.predict(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4689.922941277707"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse\n",
    "\n",
    "np.sqrt(metrics.mean_squared_error(label,pred_lm))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_scores = cross_val_score(estimator=lm , X=feat , y=label , cv=10 , scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_scores_2 = np.sqrt(-lm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [4660.93632096 4714.08386733 4711.39965045 4675.50520625 4700.16723592\n",
      " 4714.00050373 4694.18388749 4716.53058529 4725.62694482 4611.35971562]\n",
      "Mean: 4692.379391786149\n",
      "std dev 33.00076725981697\n"
     ]
    }
   ],
   "source": [
    "display_scores(lm_scores_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "    1) RMSE on training data - 4689\n",
    "    2) RMSE on validation data - 4692\n",
    "    3) Model is performing well on training data but not able to generalise on validation data.\n",
    "    4) Model might be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(scaled_feat,scaled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "pred_lm = lm.predict(scaled_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19582959377333947"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse\n",
    "\n",
    "np.sqrt(metrics.mean_squared_error(scaled_label,pred_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_scores = cross_val_score(estimator=lm , X=scaled_feat , y=scaled_label , cv=10 , scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_scores_2 = np.sqrt(-lm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.19461925 0.19683844 0.19672636 0.19522758 0.19625735 0.19683496\n",
      " 0.19600751 0.19694061 0.19732043 0.19254916]\n",
      "Mean: 0.19593216383924722\n",
      "std dev 0.001377960134459545\n"
     ]
    }
   ],
   "source": [
    "display_scores(lm_scores_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "    1) RMSE on training data - 0.195\n",
    "    2) RMSE on validation data - 0.195\n",
    "    3) Model is performing better with linear regression also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SGD regressor with learning rate 0.1 and maximum number of iterations is 1000\n",
    "sgd_reg = SGDRegressor(max_iter=1000,eta0=0.1 , penalty=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty=None, power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.fit(scaled_feat,scaled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51952621])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02629656,  0.04186411,  0.00421886, -0.32071818, -0.00398605,\n",
       "       -0.10000786])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sgd = sgd_reg.predict(scaled_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19613867074149258"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "np.sqrt(metrics.mean_squared_error(scaled_label , pred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550068, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Building network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 09:03:33.673434 139807188207424 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:72: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0730 09:03:33.691907 139807188207424 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0730 09:03:33.694983 139807188207424 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4048: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(40,input_dim = 6 , activation='relu'))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 40)                280       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 1,961\n",
      "Trainable params: 1,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observations:\n",
    "    1) There are 280 trainable parameters (6 inputs * 40 neurons + 40 biases) in input layer.\n",
    "    2) There are 1640 trainable parameters (40 inputs from layer 1 * 40 neurons + 40 biases) in hidden layer.\n",
    "    3) Total number of trainable parameters are 851\n",
    "    4) As number of neurons increases, trainable parameters increases significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> compliling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 09:03:33.896177 139807188207424 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/optimizers.py:782: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 07:48:44.561446 140439572322112 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:984: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0730 07:48:44.655095 140439572322112 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:971: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 440054 samples, validate on 110014 samples\n",
      "Epoch 1/100\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0438 - val_loss: 0.0383\n",
      "Epoch 2/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0330 - val_loss: 0.0390\n",
      "Epoch 3/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0313 - val_loss: 0.0392\n",
      "Epoch 4/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0306 - val_loss: 0.0410\n",
      "Epoch 5/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0301 - val_loss: 0.0389\n",
      "Epoch 6/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0297 - val_loss: 0.0400\n",
      "Epoch 7/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0294 - val_loss: 0.0382\n",
      "Epoch 8/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0290 - val_loss: 0.0378\n",
      "Epoch 9/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0286 - val_loss: 0.0371\n",
      "Epoch 10/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0282 - val_loss: 0.0391\n",
      "Epoch 11/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0278 - val_loss: 0.0384\n",
      "Epoch 12/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0273 - val_loss: 0.0369\n",
      "Epoch 13/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0268 - val_loss: 0.0349\n",
      "Epoch 14/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0263 - val_loss: 0.0347\n",
      "Epoch 15/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0258 - val_loss: 0.0357\n",
      "Epoch 16/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0254 - val_loss: 0.0357\n",
      "Epoch 17/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0249 - val_loss: 0.0318\n",
      "Epoch 18/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0246 - val_loss: 0.0321\n",
      "Epoch 19/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0241 - val_loss: 0.0325\n",
      "Epoch 20/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0237 - val_loss: 0.0322\n",
      "Epoch 21/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0234 - val_loss: 0.0316\n",
      "Epoch 22/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0230 - val_loss: 0.0341\n",
      "Epoch 23/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0227 - val_loss: 0.0323\n",
      "Epoch 24/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0226 - val_loss: 0.0324\n",
      "Epoch 25/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0223 - val_loss: 0.0323\n",
      "Epoch 26/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0222 - val_loss: 0.0318\n",
      "Epoch 27/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0220 - val_loss: 0.0324\n",
      "Epoch 28/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0218 - val_loss: 0.0315\n",
      "Epoch 29/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0217 - val_loss: 0.0308\n",
      "Epoch 30/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0215 - val_loss: 0.0322\n",
      "Epoch 31/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0214 - val_loss: 0.0309\n",
      "Epoch 32/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0213 - val_loss: 0.0310\n",
      "Epoch 33/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0213 - val_loss: 0.0336\n",
      "Epoch 34/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0214 - val_loss: 0.0292\n",
      "Epoch 35/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0211 - val_loss: 0.0312\n",
      "Epoch 36/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0210 - val_loss: 0.0294\n",
      "Epoch 37/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0209 - val_loss: 0.0303\n",
      "Epoch 38/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0209 - val_loss: 0.0282\n",
      "Epoch 39/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0208 - val_loss: 0.0289\n",
      "Epoch 40/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0207 - val_loss: 0.0285\n",
      "Epoch 41/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0206 - val_loss: 0.0290\n",
      "Epoch 42/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0207 - val_loss: 0.0279\n",
      "Epoch 43/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0206 - val_loss: 0.0287\n",
      "Epoch 44/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0206 - val_loss: 0.0318\n",
      "Epoch 45/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0206 - val_loss: 0.0277\n",
      "Epoch 46/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0205 - val_loss: 0.0277\n",
      "Epoch 47/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0203 - val_loss: 0.0274\n",
      "Epoch 48/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0204 - val_loss: 0.0278\n",
      "Epoch 49/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0203 - val_loss: 0.0277\n",
      "Epoch 50/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0203 - val_loss: 0.0270\n",
      "Epoch 51/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0201 - val_loss: 0.0274\n",
      "Epoch 52/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0202 - val_loss: 0.0264\n",
      "Epoch 53/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0200 - val_loss: 0.0272\n",
      "Epoch 54/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0201 - val_loss: 0.0263\n",
      "Epoch 55/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0199 - val_loss: 0.0260\n",
      "Epoch 56/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0199 - val_loss: 0.0285\n",
      "Epoch 57/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0200 - val_loss: 0.0263\n",
      "Epoch 58/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0198 - val_loss: 0.0270\n",
      "Epoch 59/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0199 - val_loss: 0.0261\n",
      "Epoch 60/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0197 - val_loss: 0.0265\n",
      "Epoch 61/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0197 - val_loss: 0.0256\n",
      "Epoch 62/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0258\n",
      "Epoch 63/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0256\n",
      "Epoch 64/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0275\n",
      "Epoch 65/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0194 - val_loss: 0.0273\n",
      "Epoch 66/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0274\n",
      "Epoch 67/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0268\n",
      "Epoch 68/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0280\n",
      "Epoch 69/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0272\n",
      "Epoch 70/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0297\n",
      "Epoch 71/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0290\n",
      "Epoch 72/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0263\n",
      "Epoch 73/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0272\n",
      "Epoch 74/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0190 - val_loss: 0.0278\n",
      "Epoch 75/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0291\n",
      "Epoch 76/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0279\n",
      "Epoch 77/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0190 - val_loss: 0.0284\n",
      "Epoch 78/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0190 - val_loss: 0.0268\n",
      "Epoch 79/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0268\n",
      "Epoch 80/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0275\n",
      "Epoch 81/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0327\n",
      "Epoch 82/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0262\n",
      "Epoch 83/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0273\n",
      "Epoch 84/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0256\n",
      "Epoch 85/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0256\n",
      "Epoch 86/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0257\n",
      "Epoch 87/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0275\n",
      "Epoch 88/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0261\n",
      "Epoch 89/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 90/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 91/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 92/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0261\n",
      "Epoch 93/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0276\n",
      "Epoch 94/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0255\n",
      "Epoch 95/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0240\n",
      "Epoch 96/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0250\n",
      "Epoch 97/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0248\n",
      "Epoch 98/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0256\n",
      "Epoch 99/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0248\n",
      "Epoch 100/100\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0184 - val_loss: 0.0248\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(scaled_feat,scaled_label,epochs=100,batch_size=5000 , verbose=1 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 440054 samples, validate on 110014 samples\n",
      "Epoch 1/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0745 - val_loss: 0.0460\n",
      "Epoch 2/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0374 - val_loss: 0.0378\n",
      "Epoch 3/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0335 - val_loss: 0.0378\n",
      "Epoch 4/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0316 - val_loss: 0.0383\n",
      "Epoch 5/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0310 - val_loss: 0.0382\n",
      "Epoch 6/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0305 - val_loss: 0.0377\n",
      "Epoch 7/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0302 - val_loss: 0.0379\n",
      "Epoch 8/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0301 - val_loss: 0.0377\n",
      "Epoch 9/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0300 - val_loss: 0.0379\n",
      "Epoch 10/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0299 - val_loss: 0.0380\n",
      "Epoch 11/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0298 - val_loss: 0.0380\n",
      "Epoch 12/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 13/500\n",
      "440054/440054 [==============================] - ETA: 0s - loss: 0.029 - 1s 1us/step - loss: 0.0297 - val_loss: 0.0381\n",
      "Epoch 14/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0296 - val_loss: 0.0388\n",
      "Epoch 15/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0296 - val_loss: 0.0384\n",
      "Epoch 16/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0294 - val_loss: 0.0381\n",
      "Epoch 17/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0293 - val_loss: 0.0378\n",
      "Epoch 18/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0292 - val_loss: 0.0384\n",
      "Epoch 19/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0291 - val_loss: 0.0379\n",
      "Epoch 20/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0289 - val_loss: 0.0377\n",
      "Epoch 21/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0288 - val_loss: 0.0393\n",
      "Epoch 22/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0287 - val_loss: 0.0382\n",
      "Epoch 23/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0285 - val_loss: 0.0380\n",
      "Epoch 24/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0284 - val_loss: 0.0371\n",
      "Epoch 25/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0281 - val_loss: 0.0364\n",
      "Epoch 26/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0279 - val_loss: 0.0369\n",
      "Epoch 27/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0277 - val_loss: 0.0383\n",
      "Epoch 28/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0274 - val_loss: 0.0370\n",
      "Epoch 29/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0271 - val_loss: 0.0374\n",
      "Epoch 30/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0269 - val_loss: 0.0366\n",
      "Epoch 31/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0267 - val_loss: 0.0361\n",
      "Epoch 32/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0263 - val_loss: 0.0355\n",
      "Epoch 33/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0260 - val_loss: 0.0366\n",
      "Epoch 34/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0258 - val_loss: 0.0340\n",
      "Epoch 35/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0255 - val_loss: 0.0356\n",
      "Epoch 36/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0252 - val_loss: 0.0346\n",
      "Epoch 37/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0249 - val_loss: 0.0343\n",
      "Epoch 38/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0247 - val_loss: 0.0326\n",
      "Epoch 39/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0244 - val_loss: 0.0313\n",
      "Epoch 40/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0241 - val_loss: 0.0317\n",
      "Epoch 41/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0238 - val_loss: 0.0316\n",
      "Epoch 42/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0237 - val_loss: 0.0292\n",
      "Epoch 43/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0234 - val_loss: 0.0306\n",
      "Epoch 44/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0233 - val_loss: 0.0292\n",
      "Epoch 45/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0229 - val_loss: 0.0284\n",
      "Epoch 46/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0228 - val_loss: 0.0293\n",
      "Epoch 47/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0227 - val_loss: 0.0288\n",
      "Epoch 48/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0224 - val_loss: 0.0328\n",
      "Epoch 49/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0226 - val_loss: 0.0288\n",
      "Epoch 50/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0222 - val_loss: 0.0272\n",
      "Epoch 51/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0220 - val_loss: 0.0285\n",
      "Epoch 52/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0221 - val_loss: 0.0268\n",
      "Epoch 53/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0218 - val_loss: 0.0285\n",
      "Epoch 54/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0218 - val_loss: 0.0271\n",
      "Epoch 55/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0216 - val_loss: 0.0268\n",
      "Epoch 56/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0216 - val_loss: 0.0266\n",
      "Epoch 57/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0214 - val_loss: 0.0280\n",
      "Epoch 58/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0215 - val_loss: 0.0261\n",
      "Epoch 59/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0213 - val_loss: 0.0279\n",
      "Epoch 60/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0214 - val_loss: 0.0254\n",
      "Epoch 61/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0210 - val_loss: 0.0256\n",
      "Epoch 62/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0210 - val_loss: 0.0246\n",
      "Epoch 63/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0210 - val_loss: 0.0248\n",
      "Epoch 64/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0209 - val_loss: 0.0247\n",
      "Epoch 65/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0208 - val_loss: 0.0243\n",
      "Epoch 66/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0207 - val_loss: 0.0246\n",
      "Epoch 67/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0206 - val_loss: 0.0254\n",
      "Epoch 68/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0207 - val_loss: 0.0240\n",
      "Epoch 69/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0205 - val_loss: 0.0250\n",
      "Epoch 70/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0205 - val_loss: 0.0251\n",
      "Epoch 71/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 72/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0204 - val_loss: 0.0241\n",
      "Epoch 73/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0203 - val_loss: 0.0242\n",
      "Epoch 74/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0203 - val_loss: 0.0239\n",
      "Epoch 75/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0202 - val_loss: 0.0236\n",
      "Epoch 76/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0202 - val_loss: 0.0262\n",
      "Epoch 77/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0203 - val_loss: 0.0242\n",
      "Epoch 78/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0201 - val_loss: 0.0236\n",
      "Epoch 79/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 80/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0200 - val_loss: 0.0234\n",
      "Epoch 81/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0200 - val_loss: 0.0253\n",
      "Epoch 82/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0201 - val_loss: 0.0245\n",
      "Epoch 83/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0200 - val_loss: 0.0244\n",
      "Epoch 84/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0199 - val_loss: 0.0264\n",
      "Epoch 85/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0201 - val_loss: 0.0290\n",
      "Epoch 86/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 87/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0198 - val_loss: 0.0246\n",
      "Epoch 88/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0198 - val_loss: 0.0246\n",
      "Epoch 89/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0198 - val_loss: 0.0233\n",
      "Epoch 90/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0197 - val_loss: 0.0233\n",
      "Epoch 91/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0197 - val_loss: 0.0244\n",
      "Epoch 92/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0221\n",
      "Epoch 93/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0197 - val_loss: 0.0232\n",
      "Epoch 94/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 95/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0195 - val_loss: 0.0233\n",
      "Epoch 96/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 97/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0195 - val_loss: 0.0248\n",
      "Epoch 98/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0195 - val_loss: 0.0228\n",
      "Epoch 99/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0194 - val_loss: 0.0242\n",
      "Epoch 100/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0194 - val_loss: 0.0247\n",
      "Epoch 101/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0195 - val_loss: 0.0247\n",
      "Epoch 102/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0194 - val_loss: 0.0236\n",
      "Epoch 103/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0195 - val_loss: 0.0235\n",
      "Epoch 104/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0195 - val_loss: 0.0236\n",
      "Epoch 105/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0255\n",
      "Epoch 106/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 107/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0217\n",
      "Epoch 108/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0237\n",
      "Epoch 109/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0232\n",
      "Epoch 110/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0240\n",
      "Epoch 111/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0256\n",
      "Epoch 112/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0271\n",
      "Epoch 113/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0230\n",
      "Epoch 114/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0239\n",
      "Epoch 115/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0232\n",
      "Epoch 116/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0254\n",
      "Epoch 117/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0245\n",
      "Epoch 118/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 119/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0250\n",
      "Epoch 120/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0225\n",
      "Epoch 121/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 122/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0230\n",
      "Epoch 123/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0236\n",
      "Epoch 124/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0243\n",
      "Epoch 125/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0190 - val_loss: 0.0253\n",
      "Epoch 126/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0273\n",
      "Epoch 127/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0191 - val_loss: 0.0232\n",
      "Epoch 128/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0246\n",
      "Epoch 129/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0267\n",
      "Epoch 130/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0190 - val_loss: 0.0244\n",
      "Epoch 131/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0190 - val_loss: 0.0249\n",
      "Epoch 132/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0276\n",
      "Epoch 133/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0236\n",
      "Epoch 134/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0227\n",
      "Epoch 135/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0249\n",
      "Epoch 136/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0236\n",
      "Epoch 137/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0244\n",
      "Epoch 138/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0189 - val_loss: 0.0232\n",
      "Epoch 139/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0233\n",
      "Epoch 140/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0252\n",
      "Epoch 141/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0249\n",
      "Epoch 142/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0233\n",
      "Epoch 143/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0239\n",
      "Epoch 144/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0261\n",
      "Epoch 145/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0237\n",
      "Epoch 146/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0259\n",
      "Epoch 147/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0228\n",
      "Epoch 148/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 149/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0250\n",
      "Epoch 150/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0188 - val_loss: 0.0235\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0251\n",
      "Epoch 152/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0240\n",
      "Epoch 153/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0187 - val_loss: 0.0238\n",
      "Epoch 154/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0271\n",
      "Epoch 155/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0186 - val_loss: 0.0243\n",
      "Epoch 156/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 157/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0249\n",
      "Epoch 158/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 159/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0236\n",
      "Epoch 160/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0184 - val_loss: 0.0236\n",
      "Epoch 161/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0184 - val_loss: 0.0263\n",
      "Epoch 162/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0256\n",
      "Epoch 163/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0184 - val_loss: 0.0279\n",
      "Epoch 164/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0252\n",
      "Epoch 165/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0183 - val_loss: 0.0247\n",
      "Epoch 166/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0183 - val_loss: 0.0240\n",
      "Epoch 167/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0183 - val_loss: 0.0251\n",
      "Epoch 168/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0183 - val_loss: 0.0253\n",
      "Epoch 169/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0183 - val_loss: 0.0278\n",
      "Epoch 170/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0182 - val_loss: 0.0271\n",
      "Epoch 171/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0183 - val_loss: 0.0316\n",
      "Epoch 172/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0185 - val_loss: 0.0251\n",
      "Epoch 173/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0182 - val_loss: 0.0267\n",
      "Epoch 174/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0182 - val_loss: 0.0252\n",
      "Epoch 175/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0241\n",
      "Epoch 176/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0245\n",
      "Epoch 177/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0259\n",
      "Epoch 178/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0182 - val_loss: 0.0256\n",
      "Epoch 179/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0276\n",
      "Epoch 180/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0184 - val_loss: 0.0275\n",
      "Epoch 181/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0294\n",
      "Epoch 182/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0182 - val_loss: 0.0258\n",
      "Epoch 183/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0180 - val_loss: 0.0243\n",
      "Epoch 184/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0180 - val_loss: 0.0290\n",
      "Epoch 185/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0249\n",
      "Epoch 186/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0180 - val_loss: 0.0271\n",
      "Epoch 187/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0180 - val_loss: 0.0282\n",
      "Epoch 188/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0252\n",
      "Epoch 189/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0179 - val_loss: 0.0251\n",
      "Epoch 190/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0180 - val_loss: 0.0262\n",
      "Epoch 191/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0179 - val_loss: 0.0279\n",
      "Epoch 192/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0181 - val_loss: 0.0233\n",
      "Epoch 193/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0179 - val_loss: 0.0250\n",
      "Epoch 194/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0269\n",
      "Epoch 195/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0271\n",
      "Epoch 196/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0268\n",
      "Epoch 197/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0281\n",
      "Epoch 198/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0281\n",
      "Epoch 199/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0179 - val_loss: 0.0300\n",
      "Epoch 200/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0179 - val_loss: 0.0256\n",
      "Epoch 201/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0267\n",
      "Epoch 202/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0268\n",
      "Epoch 203/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0278\n",
      "Epoch 204/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0268\n",
      "Epoch 205/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0292\n",
      "Epoch 206/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0295\n",
      "Epoch 207/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0180 - val_loss: 0.0261\n",
      "Epoch 208/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0266\n",
      "Epoch 209/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0176 - val_loss: 0.0286\n",
      "Epoch 210/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0301\n",
      "Epoch 211/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0176 - val_loss: 0.0278\n",
      "Epoch 212/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0176 - val_loss: 0.0282\n",
      "Epoch 213/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0176 - val_loss: 0.0335\n",
      "Epoch 214/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0293\n",
      "Epoch 215/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0177 - val_loss: 0.0266\n",
      "Epoch 216/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0305\n",
      "Epoch 217/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0178 - val_loss: 0.0391\n",
      "Epoch 218/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0179 - val_loss: 0.0273\n",
      "Epoch 219/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0299\n",
      "Epoch 220/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0176 - val_loss: 0.0270\n",
      "Epoch 221/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0295\n",
      "Epoch 222/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0282\n",
      "Epoch 223/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0273\n",
      "Epoch 224/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0265\n",
      "Epoch 225/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0287\n",
      "Epoch 226/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0283\n",
      "Epoch 227/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0281\n",
      "Epoch 228/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0292\n",
      "Epoch 229/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0363\n",
      "Epoch 230/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0310\n",
      "Epoch 231/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0287\n",
      "Epoch 232/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0289\n",
      "Epoch 233/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0278\n",
      "Epoch 234/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0288\n",
      "Epoch 235/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0314\n",
      "Epoch 236/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0318\n",
      "Epoch 237/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0296\n",
      "Epoch 238/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0282\n",
      "Epoch 239/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0175 - val_loss: 0.0316\n",
      "Epoch 240/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0344\n",
      "Epoch 241/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0348\n",
      "Epoch 242/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0321\n",
      "Epoch 243/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0304\n",
      "Epoch 244/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0321\n",
      "Epoch 245/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0358\n",
      "Epoch 246/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0308\n",
      "Epoch 247/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0296\n",
      "Epoch 248/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0316\n",
      "Epoch 249/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0307\n",
      "Epoch 250/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0330\n",
      "Epoch 251/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0353\n",
      "Epoch 252/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0357\n",
      "Epoch 253/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0173 - val_loss: 0.0308\n",
      "Epoch 254/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0405\n",
      "Epoch 255/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0324\n",
      "Epoch 256/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0326\n",
      "Epoch 257/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0286\n",
      "Epoch 258/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0375\n",
      "Epoch 259/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0300\n",
      "Epoch 260/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0311\n",
      "Epoch 261/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0301\n",
      "Epoch 262/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0281\n",
      "Epoch 263/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0320\n",
      "Epoch 264/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0320\n",
      "Epoch 265/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0306\n",
      "Epoch 266/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0305\n",
      "Epoch 267/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0342\n",
      "Epoch 268/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0172 - val_loss: 0.0320\n",
      "Epoch 269/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0294\n",
      "Epoch 270/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0354\n",
      "Epoch 271/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0314\n",
      "Epoch 272/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0336\n",
      "Epoch 273/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0312\n",
      "Epoch 274/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0329\n",
      "Epoch 275/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0326\n",
      "Epoch 276/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0361\n",
      "Epoch 277/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0326\n",
      "Epoch 278/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0354\n",
      "Epoch 279/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0325\n",
      "Epoch 280/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0338\n",
      "Epoch 281/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0364\n",
      "Epoch 282/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0349\n",
      "Epoch 283/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0378\n",
      "Epoch 284/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0380\n",
      "Epoch 285/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0368\n",
      "Epoch 286/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0337\n",
      "Epoch 287/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0359\n",
      "Epoch 288/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0369\n",
      "Epoch 289/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0340\n",
      "Epoch 290/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0420\n",
      "Epoch 291/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0171 - val_loss: 0.0345\n",
      "Epoch 292/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0355\n",
      "Epoch 293/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0383\n",
      "Epoch 294/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0391\n",
      "Epoch 295/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0405\n",
      "Epoch 296/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0386\n",
      "Epoch 297/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0358\n",
      "Epoch 298/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0397\n",
      "Epoch 299/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0356\n",
      "Epoch 300/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0374\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0345\n",
      "Epoch 302/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0355\n",
      "Epoch 303/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0389\n",
      "Epoch 304/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0334\n",
      "Epoch 305/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0422\n",
      "Epoch 306/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0356\n",
      "Epoch 307/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0388\n",
      "Epoch 308/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0388\n",
      "Epoch 309/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0355\n",
      "Epoch 310/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0386\n",
      "Epoch 311/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0391\n",
      "Epoch 312/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0400\n",
      "Epoch 313/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0369\n",
      "Epoch 314/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0371\n",
      "Epoch 315/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0396\n",
      "Epoch 316/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0373\n",
      "Epoch 317/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0332\n",
      "Epoch 318/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0337\n",
      "Epoch 319/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0370\n",
      "Epoch 320/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0362\n",
      "Epoch 321/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0368\n",
      "Epoch 322/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0340\n",
      "Epoch 323/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0321\n",
      "Epoch 324/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0344\n",
      "Epoch 325/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0429\n",
      "Epoch 326/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0170 - val_loss: 0.0349\n",
      "Epoch 327/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0333\n",
      "Epoch 328/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0364\n",
      "Epoch 329/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0354\n",
      "Epoch 330/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0356\n",
      "Epoch 331/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0427\n",
      "Epoch 332/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0364\n",
      "Epoch 333/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0352\n",
      "Epoch 334/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0318\n",
      "Epoch 335/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0349\n",
      "Epoch 336/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0338\n",
      "Epoch 337/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0341\n",
      "Epoch 338/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0391\n",
      "Epoch 339/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0341\n",
      "Epoch 340/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0373\n",
      "Epoch 341/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0447\n",
      "Epoch 342/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0336\n",
      "Epoch 343/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0352\n",
      "Epoch 344/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0399\n",
      "Epoch 345/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0392\n",
      "Epoch 346/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0368\n",
      "Epoch 347/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0366\n",
      "Epoch 348/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0395\n",
      "Epoch 349/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0344\n",
      "Epoch 350/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0368\n",
      "Epoch 351/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0315\n",
      "Epoch 352/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0371\n",
      "Epoch 353/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0346\n",
      "Epoch 354/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0313\n",
      "Epoch 355/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0328\n",
      "Epoch 356/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0354\n",
      "Epoch 357/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0349\n",
      "Epoch 358/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0362\n",
      "Epoch 359/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0351\n",
      "Epoch 360/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0406\n",
      "Epoch 361/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0345\n",
      "Epoch 362/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0360\n",
      "Epoch 363/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0375\n",
      "Epoch 364/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0364\n",
      "Epoch 365/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0386\n",
      "Epoch 366/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0371\n",
      "Epoch 367/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0380\n",
      "Epoch 368/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0347\n",
      "Epoch 369/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0415\n",
      "Epoch 370/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0367\n",
      "Epoch 371/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0362\n",
      "Epoch 372/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0429\n",
      "Epoch 373/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0399\n",
      "Epoch 374/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0376\n",
      "Epoch 375/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0355\n",
      "Epoch 376/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0414\n",
      "Epoch 377/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0403\n",
      "Epoch 378/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0323\n",
      "Epoch 379/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0361\n",
      "Epoch 380/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0343\n",
      "Epoch 381/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0399\n",
      "Epoch 382/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0352\n",
      "Epoch 383/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0331\n",
      "Epoch 384/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0366\n",
      "Epoch 385/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0376\n",
      "Epoch 386/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0355\n",
      "Epoch 387/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0350\n",
      "Epoch 388/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0347\n",
      "Epoch 389/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0344\n",
      "Epoch 390/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0339\n",
      "Epoch 391/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0405\n",
      "Epoch 392/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0339\n",
      "Epoch 393/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0395\n",
      "Epoch 394/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0350\n",
      "Epoch 395/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0380\n",
      "Epoch 396/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0400\n",
      "Epoch 397/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0374\n",
      "Epoch 398/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0375\n",
      "Epoch 399/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0381\n",
      "Epoch 400/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0360\n",
      "Epoch 401/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0358\n",
      "Epoch 402/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0395\n",
      "Epoch 403/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0386\n",
      "Epoch 404/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0384\n",
      "Epoch 405/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0345\n",
      "Epoch 406/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0359\n",
      "Epoch 407/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0351\n",
      "Epoch 408/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0395\n",
      "Epoch 409/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0346\n",
      "Epoch 410/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0338\n",
      "Epoch 411/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0348\n",
      "Epoch 412/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0370\n",
      "Epoch 413/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0370\n",
      "Epoch 414/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0346\n",
      "Epoch 415/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0370\n",
      "Epoch 416/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0342\n",
      "Epoch 417/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0351\n",
      "Epoch 418/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0386\n",
      "Epoch 419/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0377\n",
      "Epoch 420/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0444\n",
      "Epoch 421/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0340\n",
      "Epoch 422/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0365\n",
      "Epoch 423/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0321\n",
      "Epoch 424/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0373\n",
      "Epoch 425/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0371\n",
      "Epoch 426/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0368\n",
      "Epoch 427/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0373\n",
      "Epoch 428/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0397\n",
      "Epoch 429/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0376\n",
      "Epoch 430/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0447\n",
      "Epoch 431/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0345\n",
      "Epoch 432/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0360\n",
      "Epoch 433/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0357\n",
      "Epoch 434/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0340\n",
      "Epoch 435/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0339\n",
      "Epoch 436/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0364\n",
      "Epoch 437/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0373\n",
      "Epoch 438/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0358\n",
      "Epoch 439/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0347\n",
      "Epoch 440/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0352\n",
      "Epoch 441/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0346\n",
      "Epoch 442/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0369\n",
      "Epoch 443/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0444\n",
      "Epoch 444/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0361\n",
      "Epoch 445/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0350\n",
      "Epoch 446/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0382\n",
      "Epoch 447/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0409\n",
      "Epoch 448/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0358\n",
      "Epoch 449/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0361\n",
      "Epoch 450/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0368\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0445\n",
      "Epoch 452/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0330\n",
      "Epoch 453/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0351\n",
      "Epoch 454/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0338\n",
      "Epoch 455/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0346\n",
      "Epoch 456/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0358\n",
      "Epoch 457/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0372\n",
      "Epoch 458/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0342\n",
      "Epoch 459/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0377\n",
      "Epoch 460/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0380\n",
      "Epoch 461/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0347\n",
      "Epoch 462/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0359\n",
      "Epoch 463/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0336\n",
      "Epoch 464/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0336\n",
      "Epoch 465/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0344\n",
      "Epoch 466/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0362\n",
      "Epoch 467/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0315\n",
      "Epoch 468/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0334\n",
      "Epoch 469/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0347\n",
      "Epoch 470/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0354\n",
      "Epoch 471/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0350\n",
      "Epoch 472/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0329\n",
      "Epoch 473/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0357\n",
      "Epoch 474/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0334\n",
      "Epoch 475/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0354\n",
      "Epoch 476/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0368\n",
      "Epoch 477/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0351\n",
      "Epoch 478/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0322\n",
      "Epoch 479/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0365\n",
      "Epoch 480/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0296\n",
      "Epoch 481/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0333\n",
      "Epoch 482/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0348\n",
      "Epoch 483/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0361\n",
      "Epoch 484/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0349\n",
      "Epoch 485/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0322\n",
      "Epoch 486/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0357\n",
      "Epoch 487/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0342\n",
      "Epoch 488/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0335\n",
      "Epoch 489/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0325\n",
      "Epoch 490/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0342\n",
      "Epoch 491/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0313\n",
      "Epoch 492/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0339\n",
      "Epoch 493/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0311\n",
      "Epoch 494/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0161 - val_loss: 0.0327\n",
      "Epoch 495/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0340\n",
      "Epoch 496/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0164 - val_loss: 0.0320\n",
      "Epoch 497/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0163 - val_loss: 0.0335\n",
      "Epoch 498/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0323\n",
      "Epoch 499/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0161 - val_loss: 0.0334\n",
      "Epoch 500/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0162 - val_loss: 0.0322\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(scaled_feat , scaled_label , epochs=500 , batch_size=5000 , verbose=1 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation - As number of epochs increases , error on training set decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 09:03:45.363494 139807188207424 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:984: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0730 09:03:45.457362 139807188207424 deprecation_wrapper.py:119] From /usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:971: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 440054 samples, validate on 110014 samples\n",
      "Epoch 1/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0753 - val_loss: 0.0439\n",
      "Epoch 2/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0392 - val_loss: 0.0388\n",
      "Epoch 3/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0353 - val_loss: 0.0365\n",
      "Epoch 4/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0331 - val_loss: 0.0363\n",
      "Epoch 5/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0320 - val_loss: 0.0368\n",
      "Epoch 6/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0314 - val_loss: 0.0376\n",
      "Epoch 7/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0310 - val_loss: 0.0380\n",
      "Epoch 8/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0308 - val_loss: 0.0391\n",
      "Epoch 9/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0307 - val_loss: 0.0386\n",
      "Epoch 10/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0305 - val_loss: 0.0385\n",
      "Epoch 11/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0304 - val_loss: 0.0388\n",
      "Epoch 12/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0303 - val_loss: 0.0388\n",
      "Epoch 13/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0303 - val_loss: 0.0391\n",
      "Epoch 14/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0302 - val_loss: 0.0390\n",
      "Epoch 15/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0386\n",
      "Epoch 16/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0389\n",
      "Epoch 17/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0388\n",
      "Epoch 18/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0391\n",
      "Epoch 19/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0392\n",
      "Epoch 20/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 21/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0386\n",
      "Epoch 22/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 23/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0386\n",
      "Epoch 24/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0294 - val_loss: 0.0379\n",
      "Epoch 25/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0379\n",
      "Epoch 26/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0292 - val_loss: 0.0377\n",
      "Epoch 27/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 28/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0291 - val_loss: 0.0379\n",
      "Epoch 29/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0289 - val_loss: 0.0385\n",
      "Epoch 30/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0288 - val_loss: 0.0372\n",
      "Epoch 31/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0286 - val_loss: 0.0373\n",
      "Epoch 32/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0286 - val_loss: 0.0371\n",
      "Epoch 33/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0283 - val_loss: 0.0373\n",
      "Epoch 34/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0281 - val_loss: 0.0374\n",
      "Epoch 35/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0281 - val_loss: 0.0378\n",
      "Epoch 36/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0278 - val_loss: 0.0382\n",
      "Epoch 37/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0278 - val_loss: 0.0373\n",
      "Epoch 38/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0276 - val_loss: 0.0372\n",
      "Epoch 39/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0275 - val_loss: 0.0374\n",
      "Epoch 40/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0273 - val_loss: 0.0387\n",
      "Epoch 41/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0271 - val_loss: 0.0378\n",
      "Epoch 42/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0270 - val_loss: 0.0384\n",
      "Epoch 43/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0269 - val_loss: 0.0392\n",
      "Epoch 44/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0267 - val_loss: 0.0384\n",
      "Epoch 45/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0265 - val_loss: 0.0389\n",
      "Epoch 46/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0264 - val_loss: 0.0398\n",
      "Epoch 47/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0263 - val_loss: 0.0412\n",
      "Epoch 48/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0263 - val_loss: 0.0387\n",
      "Epoch 49/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0260 - val_loss: 0.0402\n",
      "Epoch 50/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0259 - val_loss: 0.0396\n",
      "Epoch 51/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0257 - val_loss: 0.0385\n",
      "Epoch 52/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0258 - val_loss: 0.0406\n",
      "Epoch 53/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0256 - val_loss: 0.0391\n",
      "Epoch 54/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0254 - val_loss: 0.0419\n",
      "Epoch 55/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0255 - val_loss: 0.0389\n",
      "Epoch 56/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0253 - val_loss: 0.0385\n",
      "Epoch 57/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0252 - val_loss: 0.0405\n",
      "Epoch 58/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0250 - val_loss: 0.0394\n",
      "Epoch 59/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0393\n",
      "Epoch 60/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0409\n",
      "Epoch 61/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0393\n",
      "Epoch 62/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0247 - val_loss: 0.0381\n",
      "Epoch 63/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0400\n",
      "Epoch 64/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0246 - val_loss: 0.0392\n",
      "Epoch 65/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0245 - val_loss: 0.0388\n",
      "Epoch 66/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0245 - val_loss: 0.0387\n",
      "Epoch 67/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0244 - val_loss: 0.0404\n",
      "Epoch 68/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0244 - val_loss: 0.0383\n",
      "Epoch 69/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0243 - val_loss: 0.0388\n",
      "Epoch 70/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0242 - val_loss: 0.0388\n",
      "Epoch 71/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0241 - val_loss: 0.0374\n",
      "Epoch 72/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0243 - val_loss: 0.0395\n",
      "Epoch 73/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0240 - val_loss: 0.0365\n",
      "Epoch 74/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0239 - val_loss: 0.0357\n",
      "Epoch 75/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0240 - val_loss: 0.0361\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0238 - val_loss: 0.0373\n",
      "Epoch 77/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0238 - val_loss: 0.0372\n",
      "Epoch 78/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0237 - val_loss: 0.0372\n",
      "Epoch 79/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0236 - val_loss: 0.0370\n",
      "Epoch 80/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0236 - val_loss: 0.0353\n",
      "Epoch 81/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0234 - val_loss: 0.0349\n",
      "Epoch 82/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0233 - val_loss: 0.0358\n",
      "Epoch 83/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0233 - val_loss: 0.0361\n",
      "Epoch 84/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0231 - val_loss: 0.0343\n",
      "Epoch 85/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0230 - val_loss: 0.0343\n",
      "Epoch 86/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0229 - val_loss: 0.0357\n",
      "Epoch 87/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0231 - val_loss: 0.0343\n",
      "Epoch 88/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0229 - val_loss: 0.0337\n",
      "Epoch 89/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0228 - val_loss: 0.0334\n",
      "Epoch 90/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0228 - val_loss: 0.0330\n",
      "Epoch 91/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0227 - val_loss: 0.0335\n",
      "Epoch 92/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0226 - val_loss: 0.0345\n",
      "Epoch 93/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0226 - val_loss: 0.0352\n",
      "Epoch 94/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0226 - val_loss: 0.0350\n",
      "Epoch 95/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0226 - val_loss: 0.0336\n",
      "Epoch 96/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0225 - val_loss: 0.0336\n",
      "Epoch 97/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0223 - val_loss: 0.0321\n",
      "Epoch 98/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0224 - val_loss: 0.0332\n",
      "Epoch 99/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0223 - val_loss: 0.0335\n",
      "Epoch 100/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0224 - val_loss: 0.0326\n",
      "Epoch 101/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.0223 - val_loss: 0.0346\n",
      "Epoch 102/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0223 - val_loss: 0.0303\n",
      "Epoch 103/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0221 - val_loss: 0.0308\n",
      "Epoch 104/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0220 - val_loss: 0.0322\n",
      "Epoch 105/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0220 - val_loss: 0.0306\n",
      "Epoch 106/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0219 - val_loss: 0.0313\n",
      "Epoch 107/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0220 - val_loss: 0.0301\n",
      "Epoch 108/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0218 - val_loss: 0.0312\n",
      "Epoch 109/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0218 - val_loss: 0.0298\n",
      "Epoch 110/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0217 - val_loss: 0.0310\n",
      "Epoch 111/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0218 - val_loss: 0.0299\n",
      "Epoch 112/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0217 - val_loss: 0.0288\n",
      "Epoch 113/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0216 - val_loss: 0.0294\n",
      "Epoch 114/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0302\n",
      "Epoch 115/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0294\n",
      "Epoch 116/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0285\n",
      "Epoch 117/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0277\n",
      "Epoch 118/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0312\n",
      "Epoch 119/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0330\n",
      "Epoch 120/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0218 - val_loss: 0.0288\n",
      "Epoch 121/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0213 - val_loss: 0.0296\n",
      "Epoch 122/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0213 - val_loss: 0.0291\n",
      "Epoch 123/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0212 - val_loss: 0.0275\n",
      "Epoch 124/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0288\n",
      "Epoch 125/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0266\n",
      "Epoch 126/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0272\n",
      "Epoch 127/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0275\n",
      "Epoch 128/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0287\n",
      "Epoch 129/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0272\n",
      "Epoch 130/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0208 - val_loss: 0.0256\n",
      "Epoch 131/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0208 - val_loss: 0.0268\n",
      "Epoch 132/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0207 - val_loss: 0.0302\n",
      "Epoch 133/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0212 - val_loss: 0.0273\n",
      "Epoch 134/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0207 - val_loss: 0.0274\n",
      "Epoch 135/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0206 - val_loss: 0.0268\n",
      "Epoch 136/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0257\n",
      "Epoch 137/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0269\n",
      "Epoch 138/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0252\n",
      "Epoch 139/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0247\n",
      "Epoch 140/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0258\n",
      "Epoch 141/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0264\n",
      "Epoch 142/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0257\n",
      "Epoch 143/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0253\n",
      "Epoch 144/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0240\n",
      "Epoch 145/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 146/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0245\n",
      "Epoch 147/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0239\n",
      "Epoch 148/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0233\n",
      "Epoch 149/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 150/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0238\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0234\n",
      "Epoch 152/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 153/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0250\n",
      "Epoch 154/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0234\n",
      "Epoch 155/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0226\n",
      "Epoch 156/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0230\n",
      "Epoch 157/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0226\n",
      "Epoch 158/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0236\n",
      "Epoch 159/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0227\n",
      "Epoch 160/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0222\n",
      "Epoch 161/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0223\n",
      "Epoch 162/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0237\n",
      "Epoch 163/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0235\n",
      "Epoch 164/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0197 - val_loss: 0.0234\n",
      "Epoch 165/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 166/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0221\n",
      "Epoch 167/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0227\n",
      "Epoch 168/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0224\n",
      "Epoch 169/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0225\n",
      "Epoch 170/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0225\n",
      "Epoch 171/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0228\n",
      "Epoch 172/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0229\n",
      "Epoch 173/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0234\n",
      "Epoch 174/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 175/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 176/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0232\n",
      "Epoch 177/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0219\n",
      "Epoch 178/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 179/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0194 - val_loss: 0.0216\n",
      "Epoch 180/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 181/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0212\n",
      "Epoch 182/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0209\n",
      "Epoch 183/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 184/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 185/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 186/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 187/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0188 - val_loss: 0.0197\n",
      "Epoch 188/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0187 - val_loss: 0.0210\n",
      "Epoch 189/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0195\n",
      "Epoch 190/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 191/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0187 - val_loss: 0.0191\n",
      "Epoch 192/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0185 - val_loss: 0.0195\n",
      "Epoch 193/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 194/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0184 - val_loss: 0.0193\n",
      "Epoch 195/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 196/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 197/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0184 - val_loss: 0.0188\n",
      "Epoch 198/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 199/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0183 - val_loss: 0.0204\n",
      "Epoch 200/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 201/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 202/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0183 - val_loss: 0.0189\n",
      "Epoch 203/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0182 - val_loss: 0.0187\n",
      "Epoch 204/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 205/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0181 - val_loss: 0.0188\n",
      "Epoch 206/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 207/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0180 - val_loss: 0.0190\n",
      "Epoch 208/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 209/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 210/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0180 - val_loss: 0.0186\n",
      "Epoch 211/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 212/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0179 - val_loss: 0.0184\n",
      "Epoch 213/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0179 - val_loss: 0.0186\n",
      "Epoch 214/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0178 - val_loss: 0.0187\n",
      "Epoch 215/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0179 - val_loss: 0.0195\n",
      "Epoch 216/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 217/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0178 - val_loss: 0.0188\n",
      "Epoch 218/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0180 - val_loss: 0.0189\n",
      "Epoch 219/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 220/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0180\n",
      "Epoch 221/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0177 - val_loss: 0.0187\n",
      "Epoch 222/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 223/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 224/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0197\n",
      "Epoch 225/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0178 - val_loss: 0.0186\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0177 - val_loss: 0.0182\n",
      "Epoch 227/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 228/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 229/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 230/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0177 - val_loss: 0.0195\n",
      "Epoch 231/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 232/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0175 - val_loss: 0.0189\n",
      "Epoch 233/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 234/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 235/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 236/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0175 - val_loss: 0.0177\n",
      "Epoch 237/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0173 - val_loss: 0.0176\n",
      "Epoch 238/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 239/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0175 - val_loss: 0.0180\n",
      "Epoch 240/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0181\n",
      "Epoch 241/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0173 - val_loss: 0.0192\n",
      "Epoch 242/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0182\n",
      "Epoch 243/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0174 - val_loss: 0.0184\n",
      "Epoch 244/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 245/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 246/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0176 - val_loss: 0.0182\n",
      "Epoch 247/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 248/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 249/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0173 - val_loss: 0.0196\n",
      "Epoch 250/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0175 - val_loss: 0.0176\n",
      "Epoch 251/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 252/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 253/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 254/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 255/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0194\n",
      "Epoch 256/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 257/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 258/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0179\n",
      "Epoch 259/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0184\n",
      "Epoch 260/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0186\n",
      "Epoch 261/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 262/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 263/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 264/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 265/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0194\n",
      "Epoch 266/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0173 - val_loss: 0.0184\n",
      "Epoch 267/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 268/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0180\n",
      "Epoch 269/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0181\n",
      "Epoch 270/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0183\n",
      "Epoch 271/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0194\n",
      "Epoch 272/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0191\n",
      "Epoch 273/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0183\n",
      "Epoch 274/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0183\n",
      "Epoch 275/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0192\n",
      "Epoch 276/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0183\n",
      "Epoch 277/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 278/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0187\n",
      "Epoch 279/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 280/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 281/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0186\n",
      "Epoch 282/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 283/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0177\n",
      "Epoch 284/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 285/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 286/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0189\n",
      "Epoch 287/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0193\n",
      "Epoch 288/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0190\n",
      "Epoch 289/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 290/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 291/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 292/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0176\n",
      "Epoch 293/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0201\n",
      "Epoch 294/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0185\n",
      "Epoch 295/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 296/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 297/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 298/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 299/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 300/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0177\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0230\n",
      "Epoch 302/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0177 - val_loss: 0.0179\n",
      "Epoch 303/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0181\n",
      "Epoch 304/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0185\n",
      "Epoch 305/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0181\n",
      "Epoch 306/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0190\n",
      "Epoch 307/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 308/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 309/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 310/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0192\n",
      "Epoch 311/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 312/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0180\n",
      "Epoch 313/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 314/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 315/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 316/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 317/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0173\n",
      "Epoch 318/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 319/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0202\n",
      "Epoch 320/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 321/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0173\n",
      "Epoch 322/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 323/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0194\n",
      "Epoch 324/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0195\n",
      "Epoch 325/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 326/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 327/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 328/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 329/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0189\n",
      "Epoch 330/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 331/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0185\n",
      "Epoch 332/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 333/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 334/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0185\n",
      "Epoch 335/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0190\n",
      "Epoch 336/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0167 - val_loss: 0.0177\n",
      "Epoch 337/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0192\n",
      "Epoch 338/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 339/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 340/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 341/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0193\n",
      "Epoch 342/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0186\n",
      "Epoch 343/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0181\n",
      "Epoch 344/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0186\n",
      "Epoch 345/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 346/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 347/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 348/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0181\n",
      "Epoch 349/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0180\n",
      "Epoch 350/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 351/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0184\n",
      "Epoch 352/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 353/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 354/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 355/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0192\n",
      "Epoch 356/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0175\n",
      "Epoch 357/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 358/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 359/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 360/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0235\n",
      "Epoch 361/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 362/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 363/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 364/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0181\n",
      "Epoch 365/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 366/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0174\n",
      "Epoch 367/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0191\n",
      "Epoch 368/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 369/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 370/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 371/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 372/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0165 - val_loss: 0.0200\n",
      "Epoch 373/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 374/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 375/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 376/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 377/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 378/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 379/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 380/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 381/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 382/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 383/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0186\n",
      "Epoch 384/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0198\n",
      "Epoch 385/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 386/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0189\n",
      "Epoch 387/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 388/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 389/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0183\n",
      "Epoch 390/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 391/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0186\n",
      "Epoch 392/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 393/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0184\n",
      "Epoch 394/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 395/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0213\n",
      "Epoch 396/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0174\n",
      "Epoch 397/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0190\n",
      "Epoch 398/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 399/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 400/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 401/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0188\n",
      "Epoch 402/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 403/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 404/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 405/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0183\n",
      "Epoch 406/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 407/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0182\n",
      "Epoch 408/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0182\n",
      "Epoch 409/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0175\n",
      "Epoch 410/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 411/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 412/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 413/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0183\n",
      "Epoch 414/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0202\n",
      "Epoch 415/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 416/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 417/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 418/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 419/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 420/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0182\n",
      "Epoch 421/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 422/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0188\n",
      "Epoch 423/500\n",
      "440054/440054 [==============================] - 1s 1us/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 424/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 425/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 426/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0203\n",
      "Epoch 427/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0182\n",
      "Epoch 428/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 429/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0184\n",
      "Epoch 430/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 431/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0195\n",
      "Epoch 432/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0227\n",
      "Epoch 433/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 434/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 435/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 436/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 437/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 438/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 439/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0179\n",
      "Epoch 440/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0172\n",
      "Epoch 441/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0194\n",
      "Epoch 442/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0211\n",
      "Epoch 443/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0177\n",
      "Epoch 444/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0182\n",
      "Epoch 445/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0190\n",
      "Epoch 446/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0194\n",
      "Epoch 447/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 448/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 449/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 450/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0211\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0220\n",
      "Epoch 452/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0191\n",
      "Epoch 453/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0194\n",
      "Epoch 454/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 455/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0195\n",
      "Epoch 456/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 457/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 458/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 459/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 460/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 461/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 462/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 463/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 464/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0194\n",
      "Epoch 465/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 466/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0189\n",
      "Epoch 467/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 468/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 469/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0182\n",
      "Epoch 470/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 471/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0199\n",
      "Epoch 472/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 473/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0182\n",
      "Epoch 474/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0199\n",
      "Epoch 475/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0181\n",
      "Epoch 476/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0181\n",
      "Epoch 477/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0181\n",
      "Epoch 478/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 479/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 480/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 481/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0170 - val_loss: 0.0179\n",
      "Epoch 482/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0188\n",
      "Epoch 483/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 484/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 485/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 486/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 487/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0221\n",
      "Epoch 488/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0171 - val_loss: 0.0179\n",
      "Epoch 489/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 490/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0191\n",
      "Epoch 491/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0178\n",
      "Epoch 492/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 493/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0209\n",
      "Epoch 494/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0166 - val_loss: 0.0176\n",
      "Epoch 495/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0164 - val_loss: 0.0203\n",
      "Epoch 496/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 497/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 498/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0167 - val_loss: 0.0181\n",
      "Epoch 499/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 500/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0165 - val_loss: 0.0175\n"
     ]
    }
   ],
   "source": [
    "history_3 = model.fit(scaled_feat , scaled_label , epochs=500 , batch_size=10000 , verbose=1 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation - Batch size is increased , but there is no change in training loss. But validation loss decreased.\n",
    "            - Model3 will be able to generalise better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb94a3bef28>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'] , 'r-',label = 'training loss')\n",
    "plt.plot(history.history['val_loss'] , 'b-' , label = 'validation loss')\n",
    "plt.title('Training vs validation loss - Case1')\n",
    "plt.xlabel('no. of epocs')\n",
    "plt.ylabel('training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb94a063278>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_2.history['loss'] , 'r-',label = 'training loss')\n",
    "plt.plot(history_2.history['val_loss'] , 'b-' , label = 'validation loss')\n",
    "plt.title('Training vs validation loss - Case2')\n",
    "plt.xlabel('no. of epocs')\n",
    "plt.ylabel('training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation - In case-2 , it took 200 epochs for the model to get to a stable error on trainng data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f26e845c630>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_3.history['loss'] , 'r-',label = 'training loss')\n",
    "plt.plot(history_3.history['val_loss'] , 'b-' , label = 'validation loss')\n",
    "plt.title('Training vs validation loss - Case3')\n",
    "plt.xlabel('no. of epocs')\n",
    "plt.ylabel('training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As number of epochs and batch size are increased validation error started to decrease and then model started to \n",
    "generalise well on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model 2 - decreasing number of input neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 440054 samples, validate on 110014 samples\n",
      "Epoch 1/500\n",
      "440054/440054 [==============================] - 1s 2us/step - loss: 0.3559 - val_loss: 0.1042\n",
      "Epoch 2/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0595 - val_loss: 0.0576\n",
      "Epoch 3/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0452 - val_loss: 0.0509\n",
      "Epoch 4/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0409 - val_loss: 0.0457\n",
      "Epoch 5/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0386 - val_loss: 0.0431\n",
      "Epoch 6/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0372 - val_loss: 0.0414\n",
      "Epoch 7/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0363 - val_loss: 0.0404\n",
      "Epoch 8/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0357 - val_loss: 0.0399\n",
      "Epoch 9/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0352 - val_loss: 0.0398\n",
      "Epoch 10/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0344 - val_loss: 0.0394\n",
      "Epoch 11/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0337 - val_loss: 0.0387\n",
      "Epoch 12/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0330 - val_loss: 0.0382\n",
      "Epoch 13/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0326 - val_loss: 0.0382\n",
      "Epoch 14/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0323 - val_loss: 0.0381\n",
      "Epoch 15/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0320 - val_loss: 0.0382\n",
      "Epoch 16/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0318 - val_loss: 0.0383\n",
      "Epoch 17/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0316 - val_loss: 0.0385\n",
      "Epoch 18/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0314 - val_loss: 0.0387\n",
      "Epoch 19/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0313 - val_loss: 0.0388\n",
      "Epoch 20/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0312 - val_loss: 0.0389\n",
      "Epoch 21/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0310 - val_loss: 0.0388\n",
      "Epoch 22/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0309 - val_loss: 0.0388\n",
      "Epoch 23/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0308 - val_loss: 0.0388\n",
      "Epoch 24/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0308 - val_loss: 0.0388\n",
      "Epoch 25/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0307 - val_loss: 0.0387\n",
      "Epoch 26/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0306 - val_loss: 0.0388\n",
      "Epoch 27/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0306 - val_loss: 0.0387\n",
      "Epoch 28/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0305 - val_loss: 0.0385\n",
      "Epoch 29/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0304 - val_loss: 0.0387\n",
      "Epoch 30/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0304 - val_loss: 0.0384\n",
      "Epoch 31/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0303 - val_loss: 0.0383\n",
      "Epoch 32/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0302 - val_loss: 0.0383\n",
      "Epoch 33/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0302 - val_loss: 0.0382\n",
      "Epoch 34/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0302 - val_loss: 0.0383\n",
      "Epoch 35/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0302 - val_loss: 0.0383\n",
      "Epoch 36/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0382\n",
      "Epoch 37/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0382\n",
      "Epoch 38/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0381\n",
      "Epoch 39/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0381\n",
      "Epoch 40/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0380\n",
      "Epoch 41/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0381\n",
      "Epoch 42/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0386\n",
      "Epoch 43/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0301 - val_loss: 0.0381\n",
      "Epoch 44/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0383\n",
      "Epoch 45/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0383\n",
      "Epoch 46/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0380\n",
      "Epoch 47/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0381\n",
      "Epoch 48/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0380\n",
      "Epoch 49/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0381\n",
      "Epoch 50/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0384\n",
      "Epoch 51/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0384\n",
      "Epoch 52/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0382\n",
      "Epoch 53/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0384\n",
      "Epoch 54/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0300 - val_loss: 0.0383\n",
      "Epoch 55/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0381\n",
      "Epoch 56/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0380\n",
      "Epoch 57/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0380\n",
      "Epoch 58/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0379\n",
      "Epoch 59/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0383\n",
      "Epoch 60/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0380\n",
      "Epoch 61/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0381\n",
      "Epoch 62/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0379\n",
      "Epoch 63/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0380\n",
      "Epoch 64/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0384\n",
      "Epoch 65/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0383\n",
      "Epoch 66/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0379\n",
      "Epoch 67/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0299 - val_loss: 0.0379\n",
      "Epoch 68/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0384\n",
      "Epoch 69/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0384\n",
      "Epoch 70/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0381\n",
      "Epoch 71/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0381\n",
      "Epoch 72/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0381\n",
      "Epoch 73/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0379\n",
      "Epoch 74/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0381\n",
      "Epoch 75/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0384\n",
      "Epoch 76/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0298 - val_loss: 0.0381\n",
      "Epoch 77/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0381\n",
      "Epoch 78/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0380\n",
      "Epoch 79/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0381\n",
      "Epoch 80/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0380\n",
      "Epoch 81/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 82/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0380\n",
      "Epoch 83/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0381\n",
      "Epoch 84/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0379\n",
      "Epoch 85/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 86/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0380\n",
      "Epoch 87/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0381\n",
      "Epoch 88/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0297 - val_loss: 0.0377\n",
      "Epoch 89/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0378\n",
      "Epoch 90/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0380\n",
      "Epoch 91/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0379\n",
      "Epoch 92/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0377\n",
      "Epoch 93/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0384\n",
      "Epoch 94/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0296 - val_loss: 0.0378\n",
      "Epoch 95/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 96/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0378\n",
      "Epoch 97/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0375\n",
      "Epoch 98/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0375\n",
      "Epoch 99/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0380\n",
      "Epoch 100/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0378\n",
      "Epoch 101/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0294 - val_loss: 0.0374\n",
      "Epoch 102/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0295 - val_loss: 0.0376\n",
      "Epoch 103/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0294 - val_loss: 0.0377\n",
      "Epoch 104/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0294 - val_loss: 0.0379\n",
      "Epoch 105/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0294 - val_loss: 0.0376\n",
      "Epoch 106/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0379\n",
      "Epoch 107/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0378\n",
      "Epoch 108/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0383\n",
      "Epoch 109/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0376\n",
      "Epoch 110/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0371\n",
      "Epoch 111/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0292 - val_loss: 0.0372\n",
      "Epoch 112/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0293 - val_loss: 0.0375\n",
      "Epoch 113/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0291 - val_loss: 0.0374\n",
      "Epoch 114/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0291 - val_loss: 0.0374\n",
      "Epoch 115/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0291 - val_loss: 0.0375\n",
      "Epoch 116/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0291 - val_loss: 0.0374\n",
      "Epoch 117/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 118/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0290 - val_loss: 0.0369\n",
      "Epoch 119/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0289 - val_loss: 0.0370\n",
      "Epoch 120/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 121/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0288 - val_loss: 0.0370\n",
      "Epoch 122/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0288 - val_loss: 0.0378\n",
      "Epoch 123/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0288 - val_loss: 0.0364\n",
      "Epoch 124/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0287 - val_loss: 0.0363\n",
      "Epoch 125/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0285 - val_loss: 0.0363\n",
      "Epoch 126/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0285 - val_loss: 0.0357\n",
      "Epoch 127/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0284 - val_loss: 0.0359\n",
      "Epoch 128/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0283 - val_loss: 0.0357\n",
      "Epoch 129/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0282 - val_loss: 0.0356\n",
      "Epoch 130/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0282 - val_loss: 0.0355\n",
      "Epoch 131/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0280 - val_loss: 0.0358\n",
      "Epoch 132/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0280 - val_loss: 0.0354\n",
      "Epoch 133/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0279 - val_loss: 0.0346\n",
      "Epoch 134/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0277 - val_loss: 0.0346\n",
      "Epoch 135/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0276 - val_loss: 0.0346\n",
      "Epoch 136/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0276 - val_loss: 0.0349\n",
      "Epoch 137/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0275 - val_loss: 0.0347\n",
      "Epoch 138/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0272 - val_loss: 0.0344\n",
      "Epoch 139/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0271 - val_loss: 0.0344\n",
      "Epoch 140/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0272 - val_loss: 0.0345\n",
      "Epoch 141/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0270 - val_loss: 0.0343\n",
      "Epoch 142/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0268 - val_loss: 0.0360\n",
      "Epoch 143/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0268 - val_loss: 0.0336\n",
      "Epoch 144/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0265 - val_loss: 0.0339\n",
      "Epoch 145/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0265 - val_loss: 0.0332\n",
      "Epoch 146/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0263 - val_loss: 0.0329\n",
      "Epoch 147/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0262 - val_loss: 0.0334\n",
      "Epoch 148/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0261 - val_loss: 0.0343\n",
      "Epoch 149/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0261 - val_loss: 0.0331\n",
      "Epoch 150/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0259 - val_loss: 0.0328\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0257 - val_loss: 0.0324\n",
      "Epoch 152/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0256 - val_loss: 0.0322\n",
      "Epoch 153/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0256 - val_loss: 0.0334\n",
      "Epoch 154/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0255 - val_loss: 0.0331\n",
      "Epoch 155/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0254 - val_loss: 0.0325\n",
      "Epoch 156/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0252 - val_loss: 0.0316\n",
      "Epoch 157/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0254 - val_loss: 0.0313\n",
      "Epoch 158/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0250 - val_loss: 0.0318\n",
      "Epoch 159/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0324\n",
      "Epoch 160/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0316\n",
      "Epoch 161/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0249 - val_loss: 0.0320\n",
      "Epoch 162/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0247 - val_loss: 0.0322\n",
      "Epoch 163/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0247 - val_loss: 0.0307\n",
      "Epoch 164/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0245 - val_loss: 0.0305\n",
      "Epoch 165/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0244 - val_loss: 0.0308\n",
      "Epoch 166/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0243 - val_loss: 0.0302\n",
      "Epoch 167/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0242 - val_loss: 0.0305\n",
      "Epoch 168/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0241 - val_loss: 0.0297\n",
      "Epoch 169/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0239 - val_loss: 0.0299\n",
      "Epoch 170/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0238 - val_loss: 0.0321\n",
      "Epoch 171/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0239 - val_loss: 0.0300\n",
      "Epoch 172/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0237 - val_loss: 0.0297\n",
      "Epoch 173/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0235 - val_loss: 0.0299\n",
      "Epoch 174/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0234 - val_loss: 0.0293\n",
      "Epoch 175/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0234 - val_loss: 0.0289\n",
      "Epoch 176/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0233 - val_loss: 0.0307\n",
      "Epoch 177/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0233 - val_loss: 0.0292\n",
      "Epoch 178/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0232 - val_loss: 0.0296\n",
      "Epoch 179/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0231 - val_loss: 0.0294\n",
      "Epoch 180/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0230 - val_loss: 0.0294\n",
      "Epoch 181/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0229 - val_loss: 0.0287\n",
      "Epoch 182/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0228 - val_loss: 0.0286\n",
      "Epoch 183/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0228 - val_loss: 0.0279\n",
      "Epoch 184/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0227 - val_loss: 0.0287\n",
      "Epoch 185/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0226 - val_loss: 0.0284\n",
      "Epoch 186/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0227 - val_loss: 0.0278\n",
      "Epoch 187/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0226 - val_loss: 0.0281\n",
      "Epoch 188/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0225 - val_loss: 0.0283\n",
      "Epoch 189/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0225 - val_loss: 0.0283\n",
      "Epoch 190/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0223 - val_loss: 0.0265\n",
      "Epoch 191/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0222 - val_loss: 0.0276\n",
      "Epoch 192/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0222 - val_loss: 0.0269\n",
      "Epoch 193/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0221 - val_loss: 0.0272\n",
      "Epoch 194/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0221 - val_loss: 0.0263\n",
      "Epoch 195/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0220 - val_loss: 0.0283\n",
      "Epoch 196/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0221 - val_loss: 0.0278\n",
      "Epoch 197/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0220 - val_loss: 0.0261\n",
      "Epoch 198/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0219 - val_loss: 0.0255\n",
      "Epoch 199/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0218 - val_loss: 0.0272\n",
      "Epoch 200/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0219 - val_loss: 0.0255\n",
      "Epoch 201/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0217 - val_loss: 0.0262\n",
      "Epoch 202/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0217 - val_loss: 0.0252\n",
      "Epoch 203/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0216 - val_loss: 0.0253\n",
      "Epoch 204/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0251\n",
      "Epoch 205/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0252\n",
      "Epoch 206/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0217 - val_loss: 0.0259\n",
      "Epoch 207/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0253\n",
      "Epoch 208/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0249\n",
      "Epoch 209/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0213 - val_loss: 0.0252\n",
      "Epoch 210/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0247\n",
      "Epoch 211/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0213 - val_loss: 0.0239\n",
      "Epoch 212/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0252\n",
      "Epoch 213/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0214 - val_loss: 0.0242\n",
      "Epoch 214/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0213 - val_loss: 0.0252\n",
      "Epoch 215/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0215 - val_loss: 0.0237\n",
      "Epoch 216/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0213 - val_loss: 0.0246\n",
      "Epoch 217/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0212 - val_loss: 0.0237\n",
      "Epoch 218/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0250\n",
      "Epoch 219/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0212 - val_loss: 0.0246\n",
      "Epoch 220/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0247\n",
      "Epoch 221/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0212 - val_loss: 0.0245\n",
      "Epoch 222/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0233\n",
      "Epoch 223/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0211 - val_loss: 0.0232\n",
      "Epoch 224/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0232\n",
      "Epoch 225/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 226/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0239\n",
      "Epoch 227/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0236\n",
      "Epoch 228/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 229/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0231\n",
      "Epoch 230/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0209 - val_loss: 0.0232\n",
      "Epoch 231/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0208 - val_loss: 0.0238\n",
      "Epoch 232/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 233/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0208 - val_loss: 0.0237\n",
      "Epoch 234/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0210 - val_loss: 0.0228\n",
      "Epoch 235/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0209 - val_loss: 0.0242\n",
      "Epoch 236/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0208 - val_loss: 0.0234\n",
      "Epoch 237/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0209 - val_loss: 0.0240\n",
      "Epoch 238/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0209 - val_loss: 0.0229\n",
      "Epoch 239/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0207 - val_loss: 0.0233\n",
      "Epoch 240/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0208 - val_loss: 0.0237\n",
      "Epoch 241/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 242/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0234\n",
      "Epoch 243/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0241\n",
      "Epoch 244/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0207 - val_loss: 0.0224\n",
      "Epoch 245/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 246/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0230\n",
      "Epoch 247/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0225\n",
      "Epoch 248/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0225\n",
      "Epoch 249/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0226\n",
      "Epoch 250/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0226\n",
      "Epoch 251/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0226\n",
      "Epoch 252/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 253/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0225\n",
      "Epoch 254/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0225\n",
      "Epoch 255/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0225\n",
      "Epoch 256/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0206 - val_loss: 0.0223\n",
      "Epoch 257/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0224\n",
      "Epoch 258/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0205 - val_loss: 0.0218\n",
      "Epoch 259/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0222\n",
      "Epoch 260/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0219\n",
      "Epoch 261/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0230\n",
      "Epoch 262/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0217\n",
      "Epoch 263/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0218\n",
      "Epoch 264/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0221\n",
      "Epoch 265/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0217\n",
      "Epoch 266/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0217\n",
      "Epoch 267/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0216\n",
      "Epoch 268/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0230\n",
      "Epoch 269/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0217\n",
      "Epoch 270/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0237\n",
      "Epoch 271/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0218\n",
      "Epoch 272/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0220\n",
      "Epoch 273/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0218\n",
      "Epoch 274/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0222\n",
      "Epoch 275/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0215\n",
      "Epoch 276/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0227\n",
      "Epoch 277/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0204 - val_loss: 0.0219\n",
      "Epoch 278/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0216\n",
      "Epoch 279/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0217\n",
      "Epoch 280/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0203 - val_loss: 0.0217\n",
      "Epoch 281/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0217\n",
      "Epoch 282/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 283/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 284/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 285/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0213\n",
      "Epoch 286/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0212\n",
      "Epoch 287/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0219\n",
      "Epoch 288/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0202 - val_loss: 0.0211\n",
      "Epoch 289/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0210\n",
      "Epoch 290/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 291/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0210\n",
      "Epoch 292/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0225\n",
      "Epoch 293/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 294/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0219\n",
      "Epoch 295/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0212\n",
      "Epoch 296/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0213\n",
      "Epoch 297/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0210\n",
      "Epoch 298/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0211\n",
      "Epoch 299/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0208\n",
      "Epoch 300/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0216\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 302/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 303/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 304/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0209\n",
      "Epoch 305/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0219\n",
      "Epoch 306/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 307/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0208\n",
      "Epoch 308/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 309/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0215\n",
      "Epoch 310/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 311/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 312/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0214\n",
      "Epoch 313/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0216\n",
      "Epoch 314/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0230\n",
      "Epoch 315/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0214\n",
      "Epoch 316/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0219\n",
      "Epoch 317/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0216\n",
      "Epoch 318/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0217\n",
      "Epoch 319/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0222\n",
      "Epoch 320/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0216\n",
      "Epoch 321/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0219\n",
      "Epoch 322/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0215\n",
      "Epoch 323/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0217\n",
      "Epoch 324/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0215\n",
      "Epoch 325/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0215\n",
      "Epoch 326/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0238\n",
      "Epoch 327/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 328/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 329/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0221\n",
      "Epoch 330/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0217\n",
      "Epoch 331/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 332/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 333/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0215\n",
      "Epoch 334/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0217\n",
      "Epoch 335/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0216\n",
      "Epoch 336/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0217\n",
      "Epoch 337/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 338/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0219\n",
      "Epoch 339/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0215\n",
      "Epoch 340/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0228\n",
      "Epoch 341/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0199 - val_loss: 0.0217\n",
      "Epoch 342/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 343/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0216\n",
      "Epoch 344/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 345/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0222\n",
      "Epoch 346/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0216\n",
      "Epoch 347/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0220\n",
      "Epoch 348/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0219\n",
      "Epoch 349/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 350/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 351/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 352/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 353/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0218\n",
      "Epoch 354/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0217\n",
      "Epoch 355/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0217\n",
      "Epoch 356/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0223\n",
      "Epoch 357/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0232\n",
      "Epoch 358/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0230\n",
      "Epoch 359/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0220\n",
      "Epoch 360/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0234\n",
      "Epoch 361/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0198 - val_loss: 0.0230\n",
      "Epoch 362/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0224\n",
      "Epoch 363/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0226\n",
      "Epoch 364/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 365/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 366/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 367/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0222\n",
      "Epoch 368/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0227\n",
      "Epoch 369/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 370/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 371/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 372/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0232\n",
      "Epoch 373/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 374/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 375/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0228\n",
      "Epoch 376/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0223\n",
      "Epoch 377/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 378/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0226\n",
      "Epoch 379/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 380/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 381/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 382/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 383/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0233\n",
      "Epoch 384/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0234\n",
      "Epoch 385/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0227\n",
      "Epoch 386/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0238\n",
      "Epoch 387/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0226\n",
      "Epoch 388/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 389/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 390/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0195 - val_loss: 0.0229\n",
      "Epoch 391/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 392/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 393/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 394/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 395/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0228\n",
      "Epoch 396/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 397/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 398/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0222\n",
      "Epoch 399/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0223\n",
      "Epoch 400/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 401/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 402/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 403/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0225\n",
      "Epoch 404/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0223\n",
      "Epoch 405/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0230\n",
      "Epoch 406/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0194 - val_loss: 0.0226\n",
      "Epoch 407/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0219\n",
      "Epoch 408/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0219\n",
      "Epoch 409/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0220\n",
      "Epoch 410/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 411/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0220\n",
      "Epoch 412/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0222\n",
      "Epoch 413/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0217\n",
      "Epoch 414/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0218\n",
      "Epoch 415/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0219\n",
      "Epoch 416/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0217\n",
      "Epoch 417/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 418/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0227\n",
      "Epoch 419/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 420/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0226\n",
      "Epoch 421/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0223\n",
      "Epoch 422/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 423/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 424/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 425/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0217\n",
      "Epoch 426/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 427/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0220\n",
      "Epoch 428/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 429/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0227\n",
      "Epoch 430/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 431/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0216\n",
      "Epoch 432/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 433/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0214\n",
      "Epoch 434/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0217\n",
      "Epoch 435/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 436/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0214\n",
      "Epoch 437/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0222\n",
      "Epoch 438/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0214\n",
      "Epoch 439/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0216\n",
      "Epoch 440/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0213\n",
      "Epoch 441/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 442/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 443/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0215\n",
      "Epoch 444/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 445/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0243\n",
      "Epoch 446/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0197 - val_loss: 0.0222\n",
      "Epoch 447/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 448/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0227\n",
      "Epoch 449/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0212\n",
      "Epoch 450/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0215\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0222\n",
      "Epoch 452/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0219\n",
      "Epoch 453/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 454/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 455/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0222\n",
      "Epoch 456/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0215\n",
      "Epoch 457/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 458/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0214\n",
      "Epoch 459/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0217\n",
      "Epoch 460/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0214\n",
      "Epoch 461/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0217\n",
      "Epoch 462/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0218\n",
      "Epoch 463/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0218\n",
      "Epoch 464/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0229\n",
      "Epoch 465/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0193 - val_loss: 0.0217\n",
      "Epoch 466/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 467/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0213\n",
      "Epoch 468/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0212\n",
      "Epoch 469/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0212\n",
      "Epoch 470/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0214\n",
      "Epoch 471/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 472/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0218\n",
      "Epoch 473/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0251\n",
      "Epoch 474/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0196 - val_loss: 0.0215\n",
      "Epoch 475/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 476/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 477/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0215\n",
      "Epoch 478/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 479/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0213\n",
      "Epoch 480/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0214\n",
      "Epoch 481/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0225\n",
      "Epoch 482/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0210\n",
      "Epoch 483/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0213\n",
      "Epoch 484/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0191 - val_loss: 0.0211\n",
      "Epoch 485/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0217\n",
      "Epoch 486/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0211\n",
      "Epoch 487/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0219\n",
      "Epoch 488/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0192 - val_loss: 0.0214\n",
      "Epoch 489/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 490/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 491/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 492/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 493/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0218\n",
      "Epoch 494/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0211\n",
      "Epoch 495/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0210\n",
      "Epoch 496/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 497/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 498/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 499/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 500/500\n",
      "440054/440054 [==============================] - 0s 1us/step - loss: 0.0189 - val_loss: 0.0213\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(20,input_dim = 6 , activation='relu'))\n",
    "model2.add(Dense(20,activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "\n",
    "model2.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "history_4 = model2.fit(scaled_feat , scaled_label , epochs=500 , batch_size=10000 , verbose=1 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation - number of neurons decreased , error increases both on training and validation data.\n",
    "            - Model's ability to learn is reduced by decreasing number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb9494b9b70>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_4.history['loss'] , 'r-',label = 'training loss')\n",
    "plt.plot(history_4.history['val_loss'] , 'b-' , label = 'validation loss')\n",
    "plt.title('Training vs validation loss - Case1')\n",
    "plt.xlabel('no. of epocs')\n",
    "plt.ylabel('training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying case 3 on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Importing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/home/monesh04246052/kaggle - practise/test_file/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000004</td>\n",
       "      <td>P00128942</td>\n",
       "      <td>M</td>\n",
       "      <td>46-50</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000009</td>\n",
       "      <td>P00113442</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>17</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000010</td>\n",
       "      <td>P00288442</td>\n",
       "      <td>F</td>\n",
       "      <td>36-45</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000010</td>\n",
       "      <td>P00145342</td>\n",
       "      <td>F</td>\n",
       "      <td>36-45</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000011</td>\n",
       "      <td>P00053842</td>\n",
       "      <td>F</td>\n",
       "      <td>26-35</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "0  1000004  P00128942      M  46-50           7             B   \n",
       "1  1000009  P00113442      M  26-35          17             C   \n",
       "2  1000010  P00288442      F  36-45           1             B   \n",
       "3  1000010  P00145342      F  36-45           1             B   \n",
       "4  1000011  P00053842      F  26-35           1             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               1                   1   \n",
       "1                          0               0                   3   \n",
       "2                         4+               1                   5   \n",
       "3                         4+               1                   4   \n",
       "4                          1               0                   4   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  \n",
       "0                11.0                 NaN  \n",
       "1                 5.0                 NaN  \n",
       "2                14.0                 NaN  \n",
       "3                 9.0                 NaN  \n",
       "4                 5.0                12.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Preprocessing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformation = ColumnTransfomer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transformation.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Marital_Status  Product_Category_1  Product_Category_2  \\\n",
       "0       0    4               1                   1                11.0   \n",
       "1       0    2               0                   3                 5.0   \n",
       "2       1    3               1                   5                14.0   \n",
       "3       1    3               1                   4                 9.0   \n",
       "4       1    2               0                   4                 5.0   \n",
       "\n",
       "   Product_Category_3  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                12.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pipeline.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pd.DataFrame(data=final_test_data , columns=test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Marital_Status  Product_Category_1  Product_Category_2  \\\n",
       "0     0.0  4.0             1.0                 1.0                11.0   \n",
       "1     0.0  2.0             0.0                 3.0                 5.0   \n",
       "2     1.0  3.0             1.0                 5.0                14.0   \n",
       "3     1.0  3.0             1.0                 4.0                 9.0   \n",
       "4     1.0  2.0             0.0                 4.0                 5.0   \n",
       "\n",
       "   Product_Category_3  \n",
       "0                16.0  \n",
       "1                16.0  \n",
       "2                16.0  \n",
       "3                16.0  \n",
       "4                12.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test data\n",
    "pred = model.predict(final_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.6107135 ],\n",
       "       [-2.1694582 ],\n",
       "       [-3.408163  ],\n",
       "       ...,\n",
       "       [-0.46897262],\n",
       "       [18.711304  ],\n",
       "       [-1.0130856 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134382.98 ],\n",
       "       [-51944.35 ],\n",
       "       [-81610.09 ],\n",
       "       ...,\n",
       "       [-11219.426],\n",
       "       [448129.03 ],\n",
       "       [-24250.389]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = pline.inverse_transform(pred)\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Puchase prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>134382.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-51944.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-81610.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>76387.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-109923.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233594</td>\n",
       "      <td>159349.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233595</td>\n",
       "      <td>-105289.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233596</td>\n",
       "      <td>-11219.425781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233597</td>\n",
       "      <td>448129.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233598</td>\n",
       "      <td>-24250.388672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233599 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted Puchase prices\n",
       "0                  134382.984375\n",
       "1                  -51944.351562\n",
       "2                  -81610.093750\n",
       "3                   76387.445312\n",
       "4                 -109923.039062\n",
       "...                          ...\n",
       "233594             159349.187500\n",
       "233595            -105289.132812\n",
       "233596             -11219.425781\n",
       "233597             448129.031250\n",
       "233598             -24250.388672\n",
       "\n",
       "[233599 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = pd.DataFrame(final_predictions)\n",
    "final_predictions.columns = ['Predicted Puchase prices']\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.concat([final_test_data,final_predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Predicted Puchase prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>134382.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-51944.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-81610.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76387.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-109923.039062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Marital_Status  Product_Category_1  Product_Category_2  \\\n",
       "0     0.0  4.0             1.0                 1.0                11.0   \n",
       "1     0.0  2.0             0.0                 3.0                 5.0   \n",
       "2     1.0  3.0             1.0                 5.0                14.0   \n",
       "3     1.0  3.0             1.0                 4.0                 9.0   \n",
       "4     1.0  2.0             0.0                 4.0                 5.0   \n",
       "\n",
       "   Product_Category_3  Predicted Puchase prices  \n",
       "0                16.0             134382.984375  \n",
       "1                16.0             -51944.351562  \n",
       "2                16.0             -81610.093750  \n",
       "3                16.0              76387.445312  \n",
       "4                12.0            -109923.039062  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
